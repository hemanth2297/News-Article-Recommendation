{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\",25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_1.csv')\n",
    "train2=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_2.csv')\n",
    "train3=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_3.csv')\n",
    "train4=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_4.csv')\n",
    "train5=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_5.csv')\n",
    "train6=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_6.csv')\n",
    "train7=pd.rewoad_csv('/Users/hemanth/Downloads/News/Train/Train_7.csv')\n",
    "train8=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_8.csv')\n",
    "train9=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_9.csv')\n",
    "train10=pd.read_csv('/Users/hemanth/Downloads/News/Train/Train_10.csv')\n",
    "train=pd.concat([train1,train2,train3,train4,train5,train6,train7,train8,train9,train10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"/Users/hemanth/Downloads/News/Item_Category_Map/Item_Category_Map_1.xlsx\")\n",
    "df2=pd.read_excel(\"/Users/hemanth/Downloads/News/Item_Category_Map/Item_Category_Map_2.xlsx\")\n",
    "cat=pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"/Users/hemanth/Downloads/News/Item_Attributes/Item_Attributes_1.csv\")\n",
    "df2=pd.read_csv(\"/Users/hemanth/Downloads/News/Item_Attributes/Item_Attributes_2.csv\")\n",
    "df3=pd.read_csv(\"/Users/hemanth/Downloads/News/Item_Attributes/Item_Attributes_3.csv\")\n",
    "att=pd.concat([df1,df2,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"/Users/hemanth/Downloads/News/sample-submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanth/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "word=pd.read_csv(\"/Users/hemanth/Downloads/News/word.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanth/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "imp=pd.read_csv(\"/Users/hemanth/Downloads/News/imp_le.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "ch=cat.copy()\n",
    "gh=pd.concat([pd.Series(row['item_id'],row['Keywords'].split(',')) for _, row in ch.iterrows()]).reset_index()\n",
    "gh1=pd.concat([pd.Series(row['item_id'],str(row['Concepts']).split(',')) for _, row in ch.iterrows()]).reset_index()\n",
    "\n",
    "ch=pd.concat([gh,gh1])\n",
    "\n",
    "ch.columns=[\"word\",\"item_id\"]\n",
    "ch=pd.concat([pd.Series(row['item_id'],row['word'].split(' '))              \n",
    "                    for _, row in ch.iterrows()]).reset_index()\n",
    "ch.columns=[\"word\",\"item_id\"]\n",
    "\n",
    "k=ch.iloc[3].word\n",
    "li=(ch[\"word\"]==k)\n",
    "ch=ch[~li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "ch[\"word\"]=ch['word'].apply(lambda x:  x if x not in stop else np.nan)\n",
    "ch[\"word\"]=ch['word'].apply(lambda x:  x if x!=\"The\" else np.nan)\n",
    "ch=ch.dropna()\n",
    "\n",
    "ch[\"word\"]= ch[\"word\"].apply(lambda x: x.lower())\n",
    "\n",
    "ch=ch.drop_duplicates()\n",
    "\n",
    "li=(ch[\"word\"]==\"null\")\n",
    "ch=ch[~li]\n",
    "word=ch.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word=word.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tag_distinct = word[[\"word\",\"item_id\"]].drop_duplicates()\n",
    "DF =Tag_distinct.groupby([\"word\"], as_index = False, sort = False).count().rename(columns = {\"item_id\": \"tag_count_DF\"})[[\"word\",\"tag_count_DF\"]]\n",
    "a=math.log10(len(np.unique(word[\"item_id\"])))\n",
    "DF[\"IDF\"]=a-np.log10(DF[\"tag_count_DF\"])\n",
    "TF = pd.merge(word,DF,on = \"word\", how = \"left\", sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanth/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "Vect_len=TF[[\"item_id\",\"IDF\"]]\n",
    "Vect_len[\"TF-IDF-Sq\"]=Vect_len[\"IDF\"]**2\n",
    "Vect_len =Vect_len.groupby([\"item_id\"], as_index = False, sort = False).sum().rename(columns = {\"TF-IDF-Sq\": \"TF-IDF-Sq-sum\"})[[\"item_id\",\"TF-IDF-Sq-sum\"]]\n",
    "Vect_len[\"vect_len\"] = np.sqrt(Vect_len[[\"TF-IDF-Sq-sum\"]].sum(axis=1))\n",
    "TF = pd.merge(TF,Vect_len,on = \"item_id\", how = \"left\", sort = False)\n",
    "TF[\"TAG_WT\"]=TF[\"IDF\"]/TF[\"vect_len\"]\n",
    "\n",
    "TF=TF[[\"item_id\",\"word\",\"TAG_WT\"]]\n",
    "TF.columns=[\"item_id\",\"word\",\"wgt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.merge(user,TF,on=[\"item_id\"],how=\"left\")\n",
    "data=data[[\"uuid\",\"word\",\"TAG_WT\"]]\n",
    "data=data.groupby([\"uuid\",\"word\"],as_index=False).sum()\n",
    "\n",
    "vect=data[[\"uuid\",\"TAG_WT\"]]\n",
    "vect[\"tf_sq\"]=vect[\"TAG_WT\"]**2\n",
    "vect=vect.groupby([\"uuid\"],as_index=False,sort=False).sum().rename(columns={\"tf_sq\":\"tf_sq_sum\"})[[\"uuid\",\"tf_sq_sum\"]]\n",
    "vect[\"vect_len\"] = np.sqrt(vect[[\"tf_sq_sum\"]].sum(axis=1))\n",
    "data=pd.merge(data,vect,on=[\"uuid\"],how=\"left\")\n",
    "data[\"TAG_WT\"]=data[\"TAG_WT\"]/data[\"vect_len\"]\n",
    "data=data[[\"uuid\",\"word\",\"TAG_WT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distinc_word=np.unique(data[\"item_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-1dbd9ce5a150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0msu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0msu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitem_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"product\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mFinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'item1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pro\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msu\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4546\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m-> 4547\u001b[0;31m                       verify_integrity=verify_integrity)\n\u001b[0m\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4549\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/reshape/concat.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    204\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/reshape/concat.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_new_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/reshape/concat.pyc\u001b[0m in \u001b[0;36m_get_new_axes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0mnew_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_comb_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/reshape/concat.pyc\u001b[0m in \u001b[0;36m_get_comb_axis\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot concatenate list of %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_combined_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_concat_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/api.pyc\u001b[0m in \u001b[0;36m_get_combined_index\u001b[0;34m(indexes, intersect)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_combined_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# TODO: handle index names!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_distinct_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/api.pyc\u001b[0m in \u001b[0;36m_get_distinct_indexes\u001b[0;34m(indexes)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_distinct_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hemanth/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/api.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_distinct_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Final=pd.DataFrame(columns=[\"item1\",\"item2\",\"pro\"])\n",
    "for item in distinc_word:\n",
    "    item1_val=data[data[\"item_id\"]==item]\n",
    "    item1_val=item1_val[[\"item_id\",\"word\",\"TAG_WT\"]]\n",
    "    for item2 in distinc_word:\n",
    "        if item2!=item:\n",
    "            item2_val=data[data[\"item_id\"]==item2]\n",
    "            item2_val=item2_val.rename(columns={\"item_id\":\"item_id2\",\"TAG_WT\":\"TAG_WT2\"})\n",
    "            item2_val=item2_val[[\"item_id2\",\"word\",\"TAG_WT2\"]]\n",
    "            item_data=pd.merge(item1_val,item2_val,on=\"word\",how=\"inner\")\n",
    "            item_data[\"product\"]=item_data[\"TAG_WT\"]*item_data[\"TAG_WT2\"]\n",
    "            su=0\n",
    "            su=item_data[\"product\"].sum()\n",
    "            Final=Final.append({'item1':item, 'item2':item2,\"pro\":su}, ignore_index=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanth/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"/Users/hemanth/Downloads/News/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"/Users/hemanth/Downloads/News/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp[\"uvh\"]=imp[\"uvh\"].str.replace(\"0-\",\",\")\n",
    "imp[\"uvh\"]=imp[\"uvh\"].str.replace(\"S\",\",\")\n",
    "imp[\"uvh\"]=imp[\"uvh\"].str.replace(\"-\",\",\")\n",
    "\n",
    "k=imp[\"uvh\"].iloc[1]\n",
    "li=(imp[\"uvh\"]==k)\n",
    "imp=imp[~li]\n",
    "\n",
    "imp1=imp[[\"uuid\",\"uvh\"]]\n",
    "imp1=imp1.drop_duplicates()\n",
    "\n",
    "user=pd.DataFrame()\n",
    "user=pd.concat([pd.Series(row['uuid'],row['uvh'].split(',')) for _, row in imp1.iterrows()]).reset_index()\n",
    "user.columns=[[\"item_id\",\"uuid\"]]\n",
    "user=user.drop_duplicates()\n",
    "user[\"len\"]=user[\"item_id\"].str.len()\n",
    "li=user[\"len\"]==8\n",
    "user1=user[li].copy()\n",
    "user1.drop([\"len\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "ids=df[\"uuid\"]\n",
    "ids2=df_test[\"uuid\"]\n",
    "iids=pd.DataFrame()\n",
    "iids[\"id\"]=pd.concat([ids,ids2])\n",
    "li=user1[\"uuid\"].isin(iids[\"id\"])\n",
    "user1=user1[li]\n",
    "\n",
    "user1.to_csv(\"/Users/hemanth/Downloads/News/user_item.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ust=df[[\"uuid\",\"item_id\"]]\n",
    "ust2=df_test[[\"uuid\",\"item_id\"]]\n",
    "ust=pd.concat([ust,ust2])\n",
    "ust=ust.drop_duplicates()\n",
    "\n",
    "li=ust[\"item_id\"].isin(TF[\"item_id\"])\n",
    "ust=ust[li]\n",
    "\n",
    "li=ust[\"uuid\"].isin(data[\"uuid\"])\n",
    "ust=ust[li]\n",
    "\n",
    "ust.item_id=ust.item_id.astype(\"str\")\n",
    "ust=pd.merge(ust,TF,on=[\"item_id\"],how=\"left\")\n",
    "ust=pd.merge(ust,data,on=[\"uuid\",\"word\"],how=\"left\")\n",
    "ust=ust.dropna()\n",
    "\n",
    "ust[\"dot\"]=ust[\"wgt\"]*ust[\"TAG_WT\"]\n",
    "ust.drop([\"word\",\"wgt\",\"TAG_WT\"],axis=1,inplace=True)\n",
    "\n",
    "ust2=ust.groupby([\"uuid\",\"item_id\"],as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch=df_test[[\"impression_id\",\"item_id\"]]\n",
    "ch=ch.drop_duplicates()\n",
    "ch[\"click\"]=np.zeros(len(ch))\n",
    "\n",
    "check=test.merge(ch,on=[\"impression_id\",\"item_id\"],how=\"left\")\n",
    "li=check[\"click\"].isnull()\n",
    "check=check[li]\n",
    "\n",
    "item=df[[\"item_id\",\"per_item\"]]\n",
    "item=item.drop_duplicates()\n",
    "\n",
    "check2=pd.merge(check,item,on=[\"item_id\"],how='left')\n",
    "li=check2[\"per_item\"]\n",
    "li[li>0.5]=2\n",
    "li[li<0.5]=1\n",
    "check2=check2.fillna(1)\n",
    "\n",
    "check2.index=check.index\n",
    "\n",
    "li=check2[\"per_item\"]\n",
    "li=li.astype(\"int\")\n",
    "\n",
    "l=sub[\"click\"]\n",
    "l.iloc[ind]=li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item=df[[\"item_id\",\"per_item\"]]\n",
    "item=item.drop_duplicates()\n",
    "\n",
    "sub2=pd.merge(sub,item,on=[\"item_id\"],how=\"left\")\n",
    "\n",
    "chec=sub2[sub2[\"per_item\"]>0.5]\n",
    "\n",
    "li=chec.index\n",
    "sub2[\"click\"].iloc[li]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop([\"impression_id\",\"refrenceUrl\",\"time\",\"hour\",\"timestamp_impression\",\"item_id\",\"uuid\",\"uvh\",\"geo\",\"site_id\",\"adunit_id\",\"no_uuid\",\"per_uuid\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.drop([\"impression_id\",\"refrenceUrl\",\"time\",\"hour\",\"timestamp_impression\",\"item_id\",\"uuid\",\"uvh\",\"geo\",\"site_id\",\"adunit_id\",\"no_uuid\",\"per_uuid\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/Users/hemanth/Downloads/News/df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"/Users/hemanth/Downloads/News/df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2=pd.read_csv(\"/Users/hemanth/Downloads/News/final_df_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train[[\"uuid\",\"item_id\",\"timestamp_impression\"]]\n",
    "train[\"timestamp_impression\"]=pd.to_datetime(train[\"timestamp_impression\"])\n",
    "train[\"timestamp_impression\"]=train[\"timestamp_impression\"].astype(\"str\")\n",
    "train['timestamp_impression']=train['timestamp_impression'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S.%f'))\n",
    "train['Day']=train['timestamp_impression'].apply(lambda x:x.day)\n",
    "train['hour']=train['timestamp_impression'].apply(lambda x:x.hour)\n",
    "train['minute']=train['timestamp_impression'].apply(lambda x:x.minute)\n",
    "train['second']=train['timestamp_impression'].apply(lambda x:x.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=test[[\"uuid\",\"item_id\",\"timestamp_impression\"]]\n",
    "test[\"timestamp_impression\"]=pd.to_datetime(test[\"timestamp_impression\"])\n",
    "test[\"timestamp_impression\"]=test[\"timestamp_impression\"].astype(\"str\")\n",
    "test['timestamp_impression']=test['timestamp_impression'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d %H:%M:%S.%f'))\n",
    "test['Day']=test['timestamp_impression'].apply(lambda x:x.day)\n",
    "test['hour']=test['timestamp_impression'].apply(lambda x:x.hour)\n",
    "test['minute']=test['timestamp_impression'].apply(lambda x:x.minute)\n",
    "test['second']=test['timestamp_impression'].apply(lambda x:x.second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"vis\"]=0\n",
    "train[\"vis\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check=pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18298218, 8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check=check.sort_values([\"Day\",\"hour\",\"minute\",\"second\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "check=check.groupby([\"uuid\",\"item_id\"],as_index=False).count().rename(columns = {\"vis\": \"no_vis\"})[[\"uuid\",\"item_id\",\"no_vis\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
